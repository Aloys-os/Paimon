# coding=utf-8
import os
import time
import threading
import base64
import re
import torch
import gradio as gr
import dashscope
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from dashscope.audio.qwen_tts_realtime import QwenTtsRealtime, QwenTtsRealtimeCallback, AudioFormat
import tempfile
import wave

# é…ç½®
BASE_MODEL_PATH = "Qwen/Qwen3-1.7B"
LORA_MODEL_PATH = "code/output/dpo_model/final_dpo_model"
DASHSCOPE_API_KEY = "sk-8f27d36b5fc2479395bfb712f1a4c258"
TTS_MODEL_NAME = "qwen3-tts-vd-realtime-2025-12-16"
TTS_VOICE_ID = "qwen-tts-vd-announcer-voice-20251224195614166-b94c"
TTS_URL = 'wss://dashscope.aliyuncs.com/api-ws/v1/realtime'
MAX_HISTORY_TURNS = 10

# åŠ è½½æ¨¡å‹
print("[ç³»ç»Ÿ] æ­£åœ¨åŠ è½½æ´¾è’™ LLM æ¨¡å‹...")

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)
model = PeftModel.from_pretrained(model, LORA_MODEL_PATH)
model.eval()
print("[ç³»ç»Ÿ] âœ… LLM æ¨¡å‹åŠ è½½å®Œæˆï¼")

# åˆå§‹åŒ–TTS
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY", DASHSCOPE_API_KEY)

class AudioCollector(QwenTtsRealtimeCallback):
    def __init__(self):
        self.complete_event = threading.Event()
        self.audio_chunks = []

    def on_open(self) -> None:
        pass

    def on_close(self, close_status_code, close_msg) -> None:
        pass

    def on_event(self, response: dict) -> None:
        event_type = response.get('type', '')
        if event_type == 'response.audio.delta':
            audio_data = base64.b64decode(response['delta'])
            self.audio_chunks.append(audio_data)
        elif event_type == 'session.finished':
            self.complete_event.set()

    def wait_for_finished(self):
        self.complete_event.wait()

    def get_audio_bytes(self):
        return b''.join(self.audio_chunks)

# åŠŸèƒ½å‡½æ•°
def clean_thought_process(text):
    print(f"\n[æ€è€ƒè¿‡ç¨‹] {text}")
    
    if not text or not text.strip():
        print("[æœ€ç»ˆè¾“å‡º] æ´¾è’™çš„å¤§è„‘è¦è¿‡è½½å•¦...æ—…è¡Œè€…è¦ä¸æ¢ä¸ªé—®é¢˜ï¼Ÿ")
        return "æ´¾è’™çš„å¤§è„‘è¦è¿‡è½½å•¦...æ—…è¡Œè€…è¦ä¸æ¢ä¸ªé—®é¢˜ï¼Ÿ"
    
    # æ¸…ç†æ ‡ç­¾
    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    cleaned = re.sub(r'<tool_call>.*?</tool_call>', '', cleaned, flags=re.DOTALL)
    cleaned = cleaned.replace('<think>', '').replace('</think>', '')
    cleaned = cleaned.replace('<tool_call>', '').replace('</tool_call>', '')
    cleaned = cleaned.strip()
    
    if not cleaned:
        print("[æœ€ç»ˆè¾“å‡º] æ´¾è’™çš„å¤§è„‘è¦è¿‡è½½å•¦...æ—…è¡Œè€…è¦ä¸æ¢ä¸ªé—®é¢˜ï¼Ÿ")
        return "æ´¾è’™çš„å¤§è„‘è¦è¿‡è½½å•¦...æ—…è¡Œè€…è¦ä¸æ¢ä¸ªé—®é¢˜ï¼Ÿ"
    
    print(f"[æœ€ç»ˆè¾“å‡º] {cleaned}")
    return cleaned

def split_text_smart(text):
    chunks = re.split(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›\n])', text)
    result = []
    current = ""
    for chunk in chunks:
        current += chunk
        if re.search(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›\n]', chunk) or len(current) > 10:
            if current.strip():
                result.append(current.strip())
            current = ""
    if current.strip():
        result.append(current)
    return result

def init_chat_history():
    system_prompt = (
        "ä½ ç°åœ¨æ˜¯ã€ŠåŸç¥ã€‹ä¸­çš„æ´¾è’™ï¼Œæ˜¯ç”¨æˆ·çš„å‘å¯¼å’Œæœ€å¥½çš„ä¼™ä¼´ã€‚"
        "ç”¨æˆ·æ˜¯'æ—…è¡Œè€…'ã€‚"
        "ä½ éœ€è¦ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š"
        "1. å§‹ç»ˆç”¨'æ´¾è’™'è‡ªç§°ï¼Œç¦æ­¢ä½¿ç”¨'æˆ‘'æˆ–'æœ¬æ—…è¡Œè€…'ã€‚"
        "2. ç§°å‘¼ç”¨æˆ·ä¸º'æ—…è¡Œè€…'ã€‚"
        "3. è¯­æ°”è¦æ´»æ³¼ã€è´ªåƒã€è´ªè´¢ï¼Œæˆ–è€…æ˜¯æœ‰ç‚¹å‚»ä¹ä¹çš„ã€‚"
        "4. å›ç­”è¦ç®€çŸ­ï¼Œ1-2å¥è¯å³å¯ã€‚"
        "5. ç›´æ¥å›ç­”ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–ä½¿ç”¨ç‰¹æ®Šæ ‡ç­¾ã€‚"
    )
    return [{"role": "system", "content": system_prompt}]

def chat_generation(user_input, history):
    history.append({"role": "user", "content": user_input})
    text = tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            temperature=0.8,
            top_p=0.8,
            do_sample=True,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
    history.append({"role": "assistant", "content": response})
    return response, history

def generate_voice(text_content):
    if not text_content:
        return None
    callback = AudioCollector()
    try:
        qwen_tts_realtime = QwenTtsRealtime(model=TTS_MODEL_NAME, callback=callback, url=TTS_URL)
        qwen_tts_realtime.connect()
        qwen_tts_realtime.update_session(
            voice=TTS_VOICE_ID,
            response_format=AudioFormat.PCM_24000HZ_MONO_16BIT,
            mode='server_commit'
        )
        for chunk in split_text_smart(text_content):
            qwen_tts_realtime.append_text(chunk)
            time.sleep(0.05)
        qwen_tts_realtime.finish()
        callback.wait_for_finished()
        audio_bytes = callback.get_audio_bytes()
        if audio_bytes:
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            with wave.open(temp_file.name, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(24000)
                wav_file.writeframes(audio_bytes)
            return temp_file.name
    except Exception as e:
        print(f"[TTS Error] {e}")
        return None

# Gradioç•Œé¢
global_chat_history = init_chat_history()

def chat_interface(message, history, enable_voice):
    global global_chat_history
    if not message.strip():
        return "", history, None
    raw_response, global_chat_history = chat_generation(message, global_chat_history)
    if len(global_chat_history) > MAX_HISTORY_TURNS * 2:
        global_chat_history = [global_chat_history[0]] + global_chat_history[-(MAX_HISTORY_TURNS*2 - 1):]
    spoken_text = clean_thought_process(raw_response)
    if history is None:
        history = []
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": spoken_text})
    audio_file = None
    if enable_voice:
        audio_file = generate_voice(spoken_text)
    return "", history, audio_file

def clear_chat():
    global global_chat_history
    global_chat_history = init_chat_history()
    return [], None

# CSSæ ·å¼
custom_css = """
.gradio-container {max-width: 1200px !important; margin: 0 auto !important; padding: 20px !important;}
#chatbot {height: 600px; overflow-y: auto;}
#voice_audio {margin-top: 10px;}
.header-text {text-align: center; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
              -webkit-background-clip: text; -webkit-text-fill-color: transparent; 
              font-size: 2.5em; font-weight: bold; margin-bottom: 10px;}
.subtitle-text {text-align: center; color: #666; font-size: 1.2em; margin-bottom: 20px;}
footer, .gradio-container .footer, .api-docs, a[href*="gradio"], 
button[aria-label="Settings"], .settings-button, .gradio-container .svelte-1gfkn6j {display: none !important;}
"""

# æ„å»ºç•Œé¢
with gr.Blocks(css=custom_css, theme=gr.themes.Soft(), title="æ´¾è’™AIå¯¹è¯") as demo:
    gr.HTML("""
        <div class="header-text">âœ¨ æ´¾è’™ AI å¯¹è¯ç³»ç»Ÿ âœ¨</div>
        <div class="subtitle-text">ä½ çš„ä¸“å±åŸç¥å‘å¯¼å’Œæœ€å¥½çš„ä¼™ä¼´</div>
    """)
    
    chatbot = gr.Chatbot(
        elem_id="chatbot",
        label="ğŸ’¬ ä¸æ´¾è’™å¯¹è¯",
        avatar_images=(None, "https://img.icons8.com/color/96/000000/star--v1.png"),
        show_label=False,
        height=600
    )
    
    audio_output = gr.Audio(
        label="ğŸ”Š æ´¾è’™çš„å£°éŸ³",
        elem_id="voice_audio",
        autoplay=True,
        visible=True
    )
    
    with gr.Row():
        msg = gr.Textbox(
            label="",
            placeholder="æ—…è¡Œè€…ï¼Œè·Ÿæ´¾è’™è¯´ç‚¹ä»€ä¹ˆå§... (æŒ‰Enterå‘é€)",
            scale=9,
            lines=1,
            max_lines=3,
            show_label=False,
            container=False
        )
        send_btn = gr.Button("å‘é€ ğŸ“¤", scale=1, variant="primary")
    
    with gr.Row():
        enable_voice = gr.Checkbox(label="ğŸµ å¯ç”¨è¯­éŸ³åˆæˆ", value=True)
        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", scale=1)
    
    gr.HTML("<br>")
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("""
            ### ğŸ“– ä½¿ç”¨è¯´æ˜
            1. **è¾“å…¥æ¶ˆæ¯**ï¼šåœ¨è¾“å…¥æ¡†è¾“å…¥ä½ æƒ³å¯¹æ´¾è’™è¯´çš„è¯
            2. **å‘é€**ï¼šç‚¹å‡»å‘é€æŒ‰é’®æˆ–æŒ‰Enteré”®
            3. **è¯­éŸ³**ï¼šå‹¾é€‰"å¯ç”¨è¯­éŸ³åˆæˆ"å¯ä»¥å¬åˆ°æ´¾è’™çš„å£°éŸ³
            4. **æ¸…ç©º**ï¼šç‚¹å‡»æ¸…ç©ºæŒ‰é’®å¯ä»¥é‡æ–°å¼€å§‹å¯¹è¯
            """)
        
        with gr.Column(scale=1):
            gr.Markdown("""
            ### ğŸ­ æ´¾è’™ç‰¹å¾
            - ğŸ– **è´ªåƒ**ï¼šå–œæ¬¢ç¾é£Ÿ
            - ğŸ’° **è´ªè´¢**ï¼šå¯¹æ‘©æ‹‰å¾ˆæ„Ÿå…´è¶£
            - ğŸŒŸ **æ´»æ³¼**ï¼šå……æ»¡å…ƒæ°”
            - ğŸ¤ **å¿ è¯š**ï¼šæ˜¯æ—…è¡Œè€…æœ€å¥½çš„ä¼™ä¼´
            """)
        
        with gr.Column(scale=1):
            gr.Markdown("""
            ### ğŸ’¡ å°è´´å£«
            è¯•ç€é—®æ´¾è’™ï¼š
            - "æ´¾è’™ï¼Œä»Šå¤©åƒä»€ä¹ˆï¼Ÿ"
            - "æˆ‘ä»¬å»å“ªé‡Œå†’é™©ï¼Ÿ"
            - "æ´¾è’™æœ€å–œæ¬¢ä»€ä¹ˆï¼Ÿ"
            - "ä½ å¯¹æ‘©æ‹‰æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ"
            """)
        
        with gr.Column(scale=1):
            gr.Markdown("""
            ### âš™ï¸ æŠ€æœ¯ä¿¡æ¯
            - **æ¨¡å‹**: Qwen3-1.7B + LoRA
            - **è¯­éŸ³**: é€šä¹‰åƒé—®TTS
            - **è®°å¿†**: ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            - **çŠ¶æ€**: âœ… å°±ç»ª
            """)
    
    msg.submit(fn=chat_interface, inputs=[msg, chatbot, enable_voice], outputs=[msg, chatbot, audio_output])
    send_btn.click(fn=chat_interface, inputs=[msg, chatbot, enable_voice], outputs=[msg, chatbot, audio_output])
    clear_btn.click(fn=clear_chat, inputs=[], outputs=[chatbot, audio_output])

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    print("\nè®¿é—®åœ°å€ï¼šhttp://localhost:7861")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        show_error=True
    )

